

import numpy as np

from base import SkoBase

def func_transformer(func):
    '''
    transform this kind of function:
    转换这种函数：
    ```
    def demo_func(x):
        x1, x2, x3 = x
        return x1 ** 2 + x2 ** 2 + x3 ** 2
    ```
    into this kind of function:
    这种功能：
    ```
    def demo_func(x):
        x1, x2, x3 = x[:,0], x[:,1], x[:,2]
        return x1 ** 2 + (x2 - 0.05) ** 2 + x3 ** 2
    ```
    getting vectorial performance if possible
    尽可能获得矢量性能
    :param func:
    :return:
    '''

    prefered_function_format = '''
    def demo_func(x):
        x1, x2, x3 = x[:, 0], x[:, 1], x[:, 2]
        return x1 ** 2 + (x2 - 0.05) ** 2 + x3 ** 2
    '''

    is_vector = getattr(func, 'is_vector', False)  # 获取is_vector属性没有返回false
    if is_vector:
        return func
    else:
        if func.__code__.co_argcount == 1:  # 返回函数参数个数
            def func_transformed(X):
                return np.array([func(x) for x in X])

            return func_transformed
        elif func.__code__.co_argcount > 1:

            def func_transformed(X):
                return np.array([func(*tuple(x)) for x in X])

            return func_transformed

    raise ValueError('''
    object function error,
    function should be like this:
    ''' + prefered_function_format)


class PSO(SkoBase):
    """
    Do PSO (Particle swarm optimization) algorithm.

    This algorithm was adapted from the earlier works of J. Kennedy and
    R.C. Eberhart in Particle Swarm Optimization [IJCNN1995]_.

    The position update can be defined as:

    .. math::

       x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)

    Where the position at the current step :math:`t` is updated using
    the computed velocity at :math:`t+1`. Furthermore, the velocity update
    is defined as:

    .. math::

       v_{ij}(t + 1) = w * v_{ij}(t) + c_{p}r_{1j}(t)[y_{ij}(t) − x_{ij}(t)]
                       + c_{g}r_{2j}(t)[\hat{y}_{j}(t) − x_{ij}(t)]

    Here, :math:`cp` and :math:`cg` are the cognitive and social parameters
    respectively. They control the particle's behavior given two choices: (1) to
    follow its *personal best* or (2) follow the swarm's *global best* position.
    Overall, this dictates if the swarm is explorative or exploitative in nature.
    In addition, a parameter :math:`w` controls the inertia of the swarm's
    movement.

    .. [IJCNN1995] J. Kennedy and R.C. Eberhart, "Particle Swarm Optimization,"
    Proceedings of the IEEE International Joint Conference on Neural
    Networks, 1995, pp. 1942-1948.

    Parameters
    --------------------
    func : function
        The func you want to do optimal
        您要优化的函数
    dim : int
        Number of dimension, which is number of parameters of func.
        维数，这是函数的参数数。
    pop : int
        Size of population, which is the number of Particles. We use 'pop' to keep accordance with GA
        种群大小，即粒子数。我们使用“pop”与GA保持一致
    max_iter : int
        Max of iter iterations
        iter迭代的最大次数
    Attributes
    ----------------------
    pbest_x : array_like, shape is (pop,dim)
        best location of every particle in history
        历史上每个粒子的最佳位置
    pbest_y : array_like, shape is (pop,1)
        best image of every particle in history
        历史上每个粒子的最佳图像
    gbest_x : array_like, shape is (1,dim)
        general best location for all particles in history
        历史上所有粒子的一般最佳位置
    gbest_y : float
        general best image  for all particles in history
        历史上所有粒子的一般最佳图像
    gbest_y_hist : list
        gbest_y of every iteration
        每次迭代的gbest_y

    Examples
    -----------------------------
    see https://scikit-opt.github.io/scikit-opt/#/en/README?id=_3-psoparticle-swarm-optimization
    """

    def __init__(self, func, dim, pop=40, max_iter=150, lb=None, ub=None, w=0.8, c1=0.5, c2=0.5):
        self.func = func_transformer(func)  # 要优化的函数
        self.w = w  # inertia  对应公式里的惯性权重，默认0.8
        self.cp, self.cg = c1, c2  # parameters to control personal best, global best respectively  学习因子1,2，默认0.5
        self.pop = pop  # number of particles 类型int,种群的大小，也就是粒子的数量。默认40
        self.dim = dim  # dimension of particles, which is the number of variables of func 维数，即函数的参数数
        self.max_iter = max_iter  # max iter 迭代的最大值 默认150

        self.has_constraints = not (lb is None and ub is None)
        self.lb = -np.ones(self.dim) if lb is None else np.array(lb)
        self.ub = np.ones(self.dim) if ub is None else np.array(ub)
        assert self.dim == len(self.lb) == len(self.ub), 'dim == len(lb) == len(ub) is not True'  # 条件为 true 正常执行
        assert np.all(self.ub > self.lb), 'upper-bound must be greater than lower-bound'

        self.X = np.random.uniform(low=self.lb, high=self.ub, size=(self.pop, self.dim))  # 粒子位置
        v_high = self.ub - self.lb
        self.V = np.random.uniform(low=-v_high, high=v_high, size=(self.pop, self.dim))  # speed of particles 粒子速度
        self.Y = self.cal_y()  # y = f(x) for all particles 所有粒子的y=f（x）
        self.pbest_x = self.X.copy()  # personal best location of every particle in history 历史上每个粒子的个人最佳位置
        self.pbest_y = self.Y.copy()  # best image of every particle in history 历史上每个粒子的最佳图像
        self.gbest_x = np.zeros((1, self.dim))  # global best location for all particles 所有粒子的全局最佳位置
        self.gbest_y = np.inf  # global best y for all particles 所有粒子的全局最佳y
        self.gbest_y_hist = []  # gbest_y of every iteration 每次迭代的gbest_y
        self.update_gbest()

        # record verbose values 记录详细值
        self.record_mode = False
        self.record_value = {'X': [], 'V': [], 'Y': []}

    def update_V(self):  # 1、更新粒子速度
        r1 = np.random.rand(self.pop, self.dim)
        r2 = np.random.rand(self.pop, self.dim)
        self.V = self.w * self.V + \
                 self.cp * r1 * (self.pbest_x - self.X) + \
                 self.cg * r2 * (self.gbest_x - self.X)
        print(self.V, '粒子速度')

    def update_X(self):  # 3、更新粒子位置
        self.X = self.X + self.V

        if self.has_constraints:
            self.X = np.clip(self.X, self.lb, self.ub)
        print(self.X,'粒子位置')

    def cal_y(self):   # 4、获取当前位置的y
        # calculate y for every x in X
        self.Y = self.func(self.X).reshape(-1, 1)
        return self.Y
        print(self.Y,'当前位置的y')

    def update_pbest(self):  # 更新当前个人最佳位置
        '''
        personal best
        :return:
        '''
        self.pbest_x = np.where(self.pbest_y > self.Y, self.X, self.pbest_x)
        self.pbest_y = np.where(self.pbest_y > self.Y, self.Y, self.pbest_y)
        print(self.pbest_x,'历史个人最佳位置')
        print(self.pbest_y,'历史个人最佳值')

    def update_gbest(self):  # 更新全局最佳位置
        '''
        global best
        :return:
        '''
        if self.gbest_y > self.Y.min():
            self.gbest_x = self.X[self.Y.argmin(), :].copy()
            self.gbest_y = self.Y.min()
        print(self.gbest_x,'全局最佳位置')
        print(self.gbest_y,'全局最佳值')

    def recorder(self):  # 记录位置速度最大/最小值
        if not self.record_mode:
            return
        self.record_value['X'].append(self.X)
        self.record_value['V'].append(self.V)
        self.record_value['Y'].append(self.Y)
        print(self.record_value, '记录位置')

    def run(self, max_iter=None):
        self.max_iter = max_iter or self.max_iter
        for iter_num in range(self.max_iter):
            self.update_V()  # 更新速度
            self.recorder()  # 记录位置 速度 最大/最小值
            self.update_X()    # 3、更新粒子位置
            self.cal_y()     # 4、获取当前位置的y
            self.update_pbest()   # 更新当前个人最佳位置
            self.update_gbest()  # 更新全局最佳位置

            self.gbest_y_hist.append(self.gbest_y)   # 存储全部全局最大/最小值
        return self

    fit = run
